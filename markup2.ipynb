{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T20:19:59.882578Z",
     "start_time": "2024-09-03T20:19:56.663161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm"
   ],
   "id": "3e2ab8afa060c4a4",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T20:20:01.670673Z",
     "start_time": "2024-09-03T20:20:00.929477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read csv file to dataframe\n",
    "df = pd.read_csv('data/data_main_upd_trim_1.csv')\n",
    "df.head()"
   ],
   "id": "1095f4e5c55445b6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   gvkey    year   naics     sale     cogs     xsga  xlr  xrd    xad  dvt  \\\n",
       "0   1001  1983.0     722  25395.0   6310.0  16435.0  NaN  0.0  1.330  0.0   \n",
       "1   1001  1984.0     722  32007.0   8171.0  20628.0  NaN  NaN  1.840  0.0   \n",
       "2   1001  1985.0     722  53798.0  13530.0  33021.0  NaN  0.0  3.039  0.0   \n",
       "3   1003  1982.0  442110  12748.0   7973.0   2869.0  NaN  NaN  0.161  0.0   \n",
       "4   1003  1983.0  442110  13793.0   8469.0   3186.0  NaN  NaN  0.154  0.0   \n",
       "\n",
       "   ...        cogs_D        xsga_D      mkvalt_D  dividend_D     capital_D  \\\n",
       "0  ...  11782.499719  30688.650218  48302.647024         0.0  23215.819176   \n",
       "1  ...  14733.406758  37195.045234  24125.931027         0.0  32151.679831   \n",
       "2  ...  23638.968456  57692.710820  70547.382691         0.0  50772.241193   \n",
       "3  ...  15472.540634   5567.630638           NaN         0.0    444.401330   \n",
       "4  ...  15813.944551   5949.135357  26301.956484         0.0    702.095070   \n",
       "\n",
       "        intan_D  xlr_D         kexp  mat1       s_g  \n",
       "0   1142.771764    NaN  3983.568519   NaN  4.024564  \n",
       "1   1137.777465    NaN  6002.025893   NaN  3.917146  \n",
       "2  22847.508537    NaN  8578.814800   NaN  3.976201  \n",
       "3      0.000000    NaN    80.254809   NaN  1.598896  \n",
       "4      0.000000    NaN   120.471468   NaN  1.628646  \n",
       "\n",
       "[5 rows x 32 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gvkey</th>\n",
       "      <th>year</th>\n",
       "      <th>naics</th>\n",
       "      <th>sale</th>\n",
       "      <th>cogs</th>\n",
       "      <th>xsga</th>\n",
       "      <th>xlr</th>\n",
       "      <th>xrd</th>\n",
       "      <th>xad</th>\n",
       "      <th>dvt</th>\n",
       "      <th>...</th>\n",
       "      <th>cogs_D</th>\n",
       "      <th>xsga_D</th>\n",
       "      <th>mkvalt_D</th>\n",
       "      <th>dividend_D</th>\n",
       "      <th>capital_D</th>\n",
       "      <th>intan_D</th>\n",
       "      <th>xlr_D</th>\n",
       "      <th>kexp</th>\n",
       "      <th>mat1</th>\n",
       "      <th>s_g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>722</td>\n",
       "      <td>25395.0</td>\n",
       "      <td>6310.0</td>\n",
       "      <td>16435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11782.499719</td>\n",
       "      <td>30688.650218</td>\n",
       "      <td>48302.647024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23215.819176</td>\n",
       "      <td>1142.771764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3983.568519</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.024564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>722</td>\n",
       "      <td>32007.0</td>\n",
       "      <td>8171.0</td>\n",
       "      <td>20628.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14733.406758</td>\n",
       "      <td>37195.045234</td>\n",
       "      <td>24125.931027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32151.679831</td>\n",
       "      <td>1137.777465</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6002.025893</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.917146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>722</td>\n",
       "      <td>53798.0</td>\n",
       "      <td>13530.0</td>\n",
       "      <td>33021.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23638.968456</td>\n",
       "      <td>57692.710820</td>\n",
       "      <td>70547.382691</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50772.241193</td>\n",
       "      <td>22847.508537</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8578.814800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.976201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>442110</td>\n",
       "      <td>12748.0</td>\n",
       "      <td>7973.0</td>\n",
       "      <td>2869.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15472.540634</td>\n",
       "      <td>5567.630638</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>444.401330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.254809</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.598896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1003</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>442110</td>\n",
       "      <td>13793.0</td>\n",
       "      <td>8469.0</td>\n",
       "      <td>3186.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15813.944551</td>\n",
       "      <td>5949.135357</td>\n",
       "      <td>26301.956484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>702.095070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.471468</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.628646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T20:20:04.281745Z",
     "start_time": "2024-09-03T20:20:03.125745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Generate id group based on 'gvkey' and drop if missing\n",
    "df['id'] = df['gvkey'].astype(str)\n",
    "df = df.dropna(subset=['id'])\n",
    "df['id'] = df['id'].astype(int)\n",
    "df.head()\n",
    "# Costshare0 = \"calibrated 0.85 (fig 1 NBER)\"\n",
    "df['costshare0'] = 0.85\n",
    "\n",
    "# Generate costshare1 = \"cogs_D/(cogs_D+kexp)\"\n",
    "df['costshare1'] = df['cogs_D'] / (df['cogs_D'] + df['kexp'])\n",
    "\n",
    "# Generate costshare2 = \"cogs_D/(cogs_D+xsga_D+kexp)\"\n",
    "df['costshare2'] = df['cogs_D'] / (df['cogs_D'] + df['xsga_D'] + df['kexp'])\n",
    "\n",
    "# Generate costshare3 = \"sga_D/(cogs_D+xsga_D+kexp)\"\n",
    "df['costshare3'] = df['xsga_D'] / (df['cogs_D'] + df['xsga_D'] + df['kexp'])\n",
    "\n",
    "# Generate costshare4 = \"capital cost share\"\n",
    "df['costshare4'] = df['kexp'] / (df['cogs_D'] + df['xsga_D'] + df['kexp'])\n",
    "\n",
    "# Generate mu_0, mu_1, mu_2 based on the loop in Stata\n",
    "for s in range(3):\n",
    "    df[f'mu_{s}'] = df[f'costshare{s}'] * (df['sale_D'] / df['cogs_D'])\n",
    "    \n",
    "for s in range(1, 3):\n",
    "    # Calculate the 1st and 99th percentiles by year\n",
    "    df[f'cs{s}_p1'] = df.groupby('year')[f'costshare{s}'].transform(lambda x: x.quantile(0.01))\n",
    "    df[f'cs{s}_p99'] = df.groupby('year')[f'costshare{s}'].transform(lambda x: x.quantile(0.99))\n",
    "    \n",
    "    # Drop rows where costshare is 0 or NaN\n",
    "    df = df[(df[f'costshare{s}'] != 0) & (~df[f'costshare{s}'].isna())]\n",
    "    \n",
    "    # Drop rows where costshare is outside the 1st and 99th percentiles\n",
    "    df = df[(df[f'costshare{s}'] >= df[f'cs{s}_p1']) & (df[f'costshare{s}'] <= df[f'cs{s}_p99'])]\n",
    "\n",
    "    # Optional: Drop the percentile columns if you no longer need them\n",
    "    df.drop([f'cs{s}_p1', f'cs{s}_p99'], axis=1, inplace=True)\n",
    "# Function to calculate summary statistics\n",
    "def summarize(df, columns):\n",
    "    summary = df[columns].agg(['mean', 'median', 'count']).T\n",
    "    return summary\n",
    "\n",
    "# Specify the columns to summarize\n",
    "columns_to_summarize = ['sale_D', 'cogs', 'capital_D', 'xlr_D', 'emp', 'xsga_D']\n",
    "\n",
    "# 1. Summary statistics for the full sample\n",
    "summary_all = summarize(df, columns_to_summarize)\n",
    "\n",
    "# 2. Summary statistics for the sample where xlr_D is not NaN\n",
    "summary_xlr = summarize(df[df['xlr_D'].notna()], columns_to_summarize)\n",
    "\n",
    "# Save the results to a text file in the working directory\n",
    "with open(\"data/sumstat.txt\", \"w\") as f:\n",
    "    f.write(\"Summary Statistics - Full Sample\\n\")\n",
    "    f.write(summary_all.to_string())\n",
    "    f.write(\"\\n\\nSummary Statistics - Sample where xlr_D is not NaN\\n\")\n",
    "    f.write(summary_xlr.to_string())\n",
    "# Calculate elasticities via np estimate cost share, median cost share\n",
    "\n",
    "# Calculate and generate mu1_med and mu2_med based on costshare1 and costshare2\n",
    "for m in range(2, 5):  # Loop over 2, 3, 4 digits of industry code\n",
    "    for c in range(1, 3): # Loop over costshare1 and costshare2\n",
    "        # Calculate the median of costshare`c' grouped by indmd (industry code) and year\n",
    "        median_column_name = f'cs{c}_med_{m}dt'\n",
    "        df[median_column_name] = df.groupby([f'ind{m}d', 'year'])[f'costshare{c}'].transform('median') # Calculate the median costshare of each industry code and year\n",
    "        \n",
    "        # Generate the mu`c'_med_`m' variable\n",
    "        mu_column_name = f'mu{c}_med_{m}'\n",
    "        if c == 1:\n",
    "            df[mu_column_name] = df[median_column_name] * (df['sale_D'] / df['cogs_D'])\n",
    "        elif c == 2:\n",
    "            df[mu_column_name] = df[median_column_name] * (df['sale_D'] / (df['cogs_D'] + df['xsga_D']))\n",
    "\n",
    "# Calculate and generate mu3_med based on costshare3\n",
    "for m in range(2, 5):\n",
    "    # Calculate the median of costshare3 grouped by ind`m'd and year\n",
    "    median_column_name = f'cs3_med_{m}dt'\n",
    "    df[median_column_name] = df.groupby([f'ind{m}d', 'year'])[f'costshare3'].transform('median')\n",
    "    \n",
    "    # Generate the mu3_med_`m' variable\n",
    "    mu_column_name = f'mu3_med_{m}'\n",
    "    df[mu_column_name] = df[median_column_name] * (df['sale_D'] / df['xsga_D'])\n",
    "\n",
    "# Calculate and generate mu4_med based on costshare4\n",
    "for m in range(2, 5):\n",
    "    # Calculate the median of costshare4 grouped by ind`m'd and year\n",
    "    median_column_name = f'cs4_med_{m}dt'\n",
    "    df[median_column_name] = df.groupby([f'ind{m}d', 'year'])[f'costshare4'].transform('median')\n",
    "    \n",
    "    # Generate the mu4_med_`m' variable\n",
    "    mu_column_name = f'mu4_med_{m}'\n",
    "    df[mu_column_name] = df[median_column_name] * (df['sale_D'] / df['kexp'])\n",
    "\n",
    "# Rename and label the variables\n",
    "rename_map = {\n",
    "    'mu1_med_2': 'mu_3',\n",
    "    'mu1_med_3': 'mu_4',\n",
    "    'mu1_med_4': 'mu_5',\n",
    "    'mu2_med_2': 'mu_6',\n",
    "    'mu2_med_3': 'mu_7',\n",
    "    'mu2_med_4': 'mu_8'\n",
    "}\n",
    "\n",
    "# Rename the columns according to the rename_map\n",
    "df.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "# Optional: Add labels (in pandas, you can store them in a dictionary)\n",
    "labels = {\n",
    "    'mu_3': \"markup median costshare 2d (cogs+rk)\",\n",
    "    'mu_4': \"markup median costshare 3d (cogs+rk)\",\n",
    "    'mu_5': \"markup median costshare 4d (cogs+rk)\",\n",
    "    'mu_6': \"markup median costshare 2d (cogs+rk+sga)\",\n",
    "    'mu_7': \"markup median costshare 3d (cogs+rk+sga)\",\n",
    "    'mu_8': \"markup median costshare 4d (cogs+rk+sga)\"\n",
    "}\n",
    "\n",
    "# For future reference, you can store these labels or print them out\n",
    "for col, label in labels.items():\n",
    "    print(f\"{col}: {label}\")\n",
    "# Calculate elasticities via PF estimation, pull parameters F(cogs, k) by period-indsutry\n",
    "\n",
    "df = df.sort_values(by='ind2d')\n",
    "\n",
    "# Merge with theta_ALLsectors (costshare of cogs by two digit industry code, one value per year)\n",
    "theta_cd = pd.read_stata(\"data/theta_ALLsectors.dta\")\n",
    "df = pd.merge(df, theta_cd[['ind2d', 'theta_c']], on='ind2d', how='left')\n",
    "# Generate mu_9\n",
    "df['mu_9'] = df['theta_c'] * (df['sale_D'] / df['cogs_D'])\n",
    "\n",
    "# Merge with theta_W_s_window.dta\n",
    "df = df.sort_values(by=['ind2d', 'year'])\n",
    "theta_w = pd.read_stata(\"data/theta_W_s_window.dta\")\n",
    "\n",
    "# Transfer theta_w datetime64 to int and keeping only the year\n",
    "theta_w['year'] = theta_w['year'].dt.year\n",
    "theta_w['year'] = theta_w['year'].astype(int) \n",
    "df['year'] = df['year'].astype(int)\n",
    "# Merge df and theta_w based on 'ind2d' and 'year'\n",
    "df = pd.merge(df, theta_w[['ind2d', 'year', 'theta_WI1_ct', 'theta_WI2_ct', 'theta_WI2_xt', 'theta_WI1_kt',  'theta_WI2_kt']], on=['ind2d', 'year'], how='left')\n",
    "df.head()\n",
    "#  Generate mu_10, mu_11, mu_12\n",
    "df['mu_10'] = df['theta_WI1_ct'] * (df['sale_D'] / df['cogs_D'])\n",
    "df['mu_11'] = df['theta_WI2_ct'] * (df['sale_D'] / df['cogs_D'])\n",
    "df['mu_12'] = df['theta_WI2_xt'] * (df['sale_D'] / df['xsga_D'])\n",
    "\n",
    "# Rename and label variables\n",
    "df.rename(columns={'mu3_med_2': 'mu_13'}, inplace=True)\n",
    "\n",
    "# Generate additional variables\n",
    "df['mu_14'] = df['costshare3'] * (df['sale_D'] / df['xsga_D'])\n",
    "df['mu_cap'] = df['theta_WI1_kt'] * (df['sale_D'] / df['kexp'])\n",
    "# Merge with theta_ms_window.dta\n",
    "df = df.sort_values(by=['ind2d', 'year'])\n",
    "theta_ms = pd.read_stata(\"data/theta_ms_window.dta\")\n",
    "\n",
    "# Transfer theta_w datetime64 to int and keeping only the year\n",
    "theta_ms['year'] = theta_ms['year'].dt.year\n",
    "theta_ms['year'] = theta_ms['year'].astype(int) \n",
    "df['year'] = df['year'].astype(int)\n",
    "\n",
    "# Merge df and theta_ms based on 'ind2d' and 'year'\n",
    "df = pd.merge(df, theta_ms[['ind2d', 'year', 'theta_CM1_ct', 'theta_CM2_ct', 'theta_CM2_xt', 'theta_CM1_kt', 'theta_CM2_kt']], on=['ind2d', 'year'], how='left')\n",
    "# Generate mu_15 and mu_16\n",
    "df['mu_15'] = df['theta_CM1_ct'] * (df['sale_D'] / df['cogs_D'])\n",
    "df['mu_16'] = df['theta_CM2_ct'] * (df['sale_D'] / df['cogs_D'])\n",
    "\n",
    "# Calculate total costs and sales\n",
    "df['totcost1'] = df['cogs_D'] + df['kexp']\n",
    "df['totcost2'] = df['cogs_D'] + df['xsga_D'] + df['kexp']\n",
    "\n",
    "# Aggregate values by year\n",
    "df['TOTSALES'] = df.groupby('year')['sale_D'].transform('sum')\n",
    "df['TOTCOST1'] = df.groupby('year')['totcost1'].transform('sum')\n",
    "df['TOTCOST2'] = df.groupby('year')['totcost2'].transform('sum')\n",
    "df['TOTEMP'] = df.groupby('year')['emp'].transform('sum')\n",
    "\n",
    "df['TOTCOGS'] = df.groupby('year')['cogs_D'].transform('sum')\n",
    "df['TOTSGA'] = df.groupby('year')['xsga_D'].transform('sum')\n",
    "df['TOTK'] = df.groupby('year')['capital_D'].transform('sum')\n",
    "df['TOTrK'] = df.groupby('year')['kexp'].transform('sum')\n",
    "\n",
    "# Generate cost share ratios\n",
    "df['cs_red_tot'] = df['TOTCOGS'] / df['TOTCOST1']\n",
    "df['cs_blue_tot'] = df['TOTCOGS'] / df['TOTCOST2']\n",
    "df['cs_red_k_tot'] = df['TOTK'] / df['TOTCOST1']\n",
    "df['cs_red_rk_tot'] = df['TOTrK'] / df['TOTCOST1']\n",
    "df['cs_blue_k_tot'] = df['TOTK'] / df['TOTCOST2']\n",
    "df['cs_blue_rk_tot'] = df['TOTrK'] / df['TOTCOST2']\n",
    "df['cs_blue_x_tot'] = df['TOTSGA'] / df['TOTCOST2']\n",
    "\n",
    "#  Calculate the total cost ratio\n",
    "df['m_totcost'] = df['totcost2'] / df['TOTCOST2']\n"
   ],
   "id": "9f6a1d81a5fe2fe4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu_3: markup median costshare 2d (cogs+rk)\n",
      "mu_4: markup median costshare 3d (cogs+rk)\n",
      "mu_5: markup median costshare 4d (cogs+rk)\n",
      "mu_6: markup median costshare 2d (cogs+rk+sga)\n",
      "mu_7: markup median costshare 3d (cogs+rk+sga)\n",
      "mu_8: markup median costshare 4d (cogs+rk+sga)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T20:20:05.754872Z",
     "start_time": "2024-09-03T20:20:05.079819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate Industry-Year Totals\n",
    "df['cogstot'] = df.groupby(['ind2d', 'year'])['cogs_D'].transform('sum')\n",
    "df['xtot'] = df.groupby(['ind2d', 'year'])['xsga_D'].transform('sum')\n",
    "df['ktot'] = df.groupby(['ind2d', 'year'])['kexp'].transform('sum')\n",
    "df['totcost'] = df.groupby(['ind2d', 'year'])[['xsga_D', 'cogs_D', 'kexp']].transform('sum').sum(axis=1)\n",
    "df['totsales'] = df.groupby(['ind2d', 'year'])['sale_D'].transform('sum')\n",
    "# Generating Industry-Year cost shares\n",
    "df['CS_TOT_C'] = df['cogstot'] / df['totcost']\n",
    "df['CS_TOT_X'] = df['xtot'] / df['totcost']\n",
    "df['CS_TOT_K'] = 1 - df['CS_TOT_C'] - df['CS_TOT_X']\n",
    "# Calculating inputs and their logs\n",
    "df['INPUT1'] = (df['cogs_D'] ** df['costshare2']) * (df['xsga_D'] ** df['costshare3']) * (df['capital_D'] ** (1 - df['costshare2'] - df['costshare3']))\n",
    "df['input1'] = np.log(df['INPUT1'])\n",
    "\n",
    "df['INPUT2'] = (df['cogs_D'] ** df['CS_TOT_C']) * (df['xsga_D'] ** df['CS_TOT_X']) * (df['capital_D'] ** (1 - df['CS_TOT_C'] - df['CS_TOT_X']))\n",
    "df['input2'] = np.log(df['INPUT2'])\n",
    "\n",
    "# Initialize gamma_RTS columns\n",
    "df['gamma_RTS1'] = np.nan\n",
    "df['gamma_RTS2'] = np.nan\n",
    "\n",
    "# Log of sales\n",
    "df['y'] = np.log(df['sale_D'])\n",
    "\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)  # Replace inf with NaN\n",
    "df.dropna(subset=['input1', 'input2', 'y', 'totsales'], inplace=True)  # Drop rows with NaN\n",
    "\n",
    "# Run regressions for each input and each year\n",
    "for s in range(1, 3):\n",
    "    for t in range(1955, 2017):\n",
    "        subset = df[df['year'] == t]\n",
    "        if not subset.empty:\n",
    "            X = subset[f'input{s}']\n",
    "            X = sm.add_constant(X)\n",
    "            y = subset['y']\n",
    "            w = subset['totsales']\n",
    "\n",
    "            # Weighted regression\n",
    "            model = sm.WLS(y, X, weights=w)\n",
    "            results = model.fit()\n",
    "\n",
    "            # Save the coefficient of input to gamma_RTS\n",
    "            df.loc[df['year'] == t, f'gamma_RTS{s}'] = results.params[f'input{s}']\n",
    "\n",
    "# Save results\n",
    "gamma_df = df[['year', 'gamma_RTS1', 'gamma_RTS2']].drop_duplicates().sort_values(by='year')\n",
    "gamma_df = gamma_df.drop_duplicates(subset='year')  # Drop duplicates based on year\n",
    "\n",
    "# Save the DataFrame\n",
    "gamma_df.to_csv(r'data\\gamma_syverson.csv', index=False)\n",
    "\n"
   ],
   "id": "92128c325e0c0609",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jueming\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\jueming\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T20:20:08.377068Z",
     "start_time": "2024-09-03T20:20:08.359511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df['share_firm_agg'] = df['sale_D'] / df['TOTSALES']\n",
    "df['pr'] = (df['sale_D'] - df['cogs_D'] - df['xsga_D'] - df['kexp']) / df['sale_D']\n",
    "df['pr_alt'] = (df['sale_D'] - df['cogs_D'] - df['xsga_D'] - 0.1 * df['capital_D']) / df['sale_D']\n",
    "df['F'] = df.groupby('year')['xsga_D'].transform('sum') + df.groupby('year')['kexp'].transform('sum')\n"
   ],
   "id": "fbdcc8a1e29e776a",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T20:20:26.816212Z",
     "start_time": "2024-09-03T20:20:26.797786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Weighted cost shares\n",
    "for c in range(1, 4):\n",
    "    df[f'costshare{c}_w'] = df[f'costshare{c}'] * df['share_firm_agg']\n",
    "    df[f'COSTSHARE{c}_AGG'] = df.groupby('year')[f'costshare{c}_w'].transform('sum')"
   ],
   "id": "5644115a80128a9b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T20:20:28.402585Z",
     "start_time": "2024-09-03T20:20:27.761257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Theta calculations\n",
    "theta_cols = ['theta_WI1_ct', 'theta_WI1_kt', 'theta_WI2_ct', 'theta_WI2_xt', 'theta_WI2_kt', 'cs1_med_2dt', 'cs3_med_2dt']\n",
    "for theta in theta_cols:\n",
    "    df[f'theta_{theta}'] = df.groupby('year').apply(lambda x: (x['share_firm_agg'] * x[theta]).sum()).reset_index(drop=True)\n"
   ],
   "id": "1e5988d26e79de09",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jueming\\AppData\\Local\\Temp\\ipykernel_41608\\2967693460.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[f'theta_{theta}'] = df.groupby('year').apply(lambda x: (x['share_firm_agg'] * x[theta]).sum()).reset_index(drop=True)\n",
      "C:\\Users\\jueming\\AppData\\Local\\Temp\\ipykernel_41608\\2967693460.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[f'theta_{theta}'] = df.groupby('year').apply(lambda x: (x['share_firm_agg'] * x[theta]).sum()).reset_index(drop=True)\n",
      "C:\\Users\\jueming\\AppData\\Local\\Temp\\ipykernel_41608\\2967693460.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[f'theta_{theta}'] = df.groupby('year').apply(lambda x: (x['share_firm_agg'] * x[theta]).sum()).reset_index(drop=True)\n",
      "C:\\Users\\jueming\\AppData\\Local\\Temp\\ipykernel_41608\\2967693460.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[f'theta_{theta}'] = df.groupby('year').apply(lambda x: (x['share_firm_agg'] * x[theta]).sum()).reset_index(drop=True)\n",
      "C:\\Users\\jueming\\AppData\\Local\\Temp\\ipykernel_41608\\2967693460.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[f'theta_{theta}'] = df.groupby('year').apply(lambda x: (x['share_firm_agg'] * x[theta]).sum()).reset_index(drop=True)\n",
      "C:\\Users\\jueming\\AppData\\Local\\Temp\\ipykernel_41608\\2967693460.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[f'theta_{theta}'] = df.groupby('year').apply(lambda x: (x['share_firm_agg'] * x[theta]).sum()).reset_index(drop=True)\n",
      "C:\\Users\\jueming\\AppData\\Local\\Temp\\ipykernel_41608\\2967693460.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[f'theta_{theta}'] = df.groupby('year').apply(lambda x: (x['share_firm_agg'] * x[theta]).sum()).reset_index(drop=True)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e95acc147f5b34a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c7ef449d7fd14ef0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
